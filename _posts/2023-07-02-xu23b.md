---
abstract: Vision Transformer (ViT) has achieved remarkable performance in computer
  vision. However, positional encoding in ViT makes it substantially difficult to
  learn the intrinsic equivariance in data. Ini- tial attempts have been made on designing
  equiv- ariant ViT but are proved defective in some cases in this paper. To address
  this issue, we design a Group Equivariant Vision Transformer (GE-ViT) via a novel,
  effective positional encoding opera- tor. We prove that GE-ViT meets all the theoreti-
  cal requirements of an equivariant neural network. Comprehensive experiments are
  conducted on standard benchmark datasets, demonstrating that GE-ViT significantly
  outperforms non-equivariant self-attention networks. The code is available at https://github.com/ZJUCDSYangKaifan/GEVit.
openreview: h9Ynd6F2B1M
title: "$E(2)$-Equivariant Vision Transformer"
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu23b
month: 0
tex_title: "$E(2)$-Equivariant Vision Transformer"
firstpage: 2356
lastpage: 2366
page: 2356-2366
order: 2356
cycles: false
bibtex_author: Xu, Renjun and Yang, Kaifan and Liu, Ke and He, Fengxiang
author:
- given: Renjun
  family: Xu
- given: Kaifan
  family: Yang
- given: Ke
  family: Liu
- given: Fengxiang
  family: He
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/xu23b/xu23b.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/xu23b/xu23b-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
