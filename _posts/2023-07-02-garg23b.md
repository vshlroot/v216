---
abstract: Detecting out-of-distribution (OOD) samples is a problem of practical importance
  for a reliable use of deep neural networks (DNNs) in production settings. The corollary
  to this problem is the detection in-distribution (ID) samples, which is applicable
  to domain adaptation scenarios for augmenting a train set with ID samples from other
  data sets, or to continual learning for replay from the past. For both ID or OOD
  detection, we propose a principled yet simple approach of (empirically) estimating
  KL-Divergence, in its dual form, for a given test set w.r.t. a known set of ID samples
  in order to quantify the contribution of each test sample individually towards the
  divergence measure and accordingly detect it as OOD or ID. Our approach is compute-efficient
  and enjoys strong theoretical guarantees. For WideResnet101 and ViT-L-16, by considering
  ImageNet-1k dataset as the ID benchmark, we evaluate the proposed OOD detector on
  51 test (OOD) datasets, and observe drastically and consistently lower false positive
  rates w.r.t. all the competitive methods. Moreover, the proposed ID detector is
  evaluated, using ECG and stock price datasets, for the task of data augmentation
  in domain adaptation and continual learning settings, and we observe higher efficacy
  compared to relevant baselines.
openreview: w1MR5reJo7
title: In- or out-of-distribution detection via dual divergence estimation
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: garg23b
month: 0
tex_title: In- or out-of-distribution detection via dual divergence estimation
firstpage: 635
lastpage: 646
page: 635-646
order: 635
cycles: false
bibtex_author: Garg, Sahil and Dutta, Sanghamitra and Dalirrooyfard, Mina and Schneider,
  Anderson and Nevmyvaka, Yuriy
author:
- given: Sahil
  family: Garg
- given: Sanghamitra
  family: Dutta
- given: Mina
  family: Dalirrooyfard
- given: Anderson
  family: Schneider
- given: Yuriy
  family: Nevmyvaka
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/garg23b/garg23b.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/garg23b/garg23b-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
