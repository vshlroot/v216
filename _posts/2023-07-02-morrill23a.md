---
abstract: Modern reinforcement learning systems produce many high-quality policies
  throughout the learning process. However, to choose which policy to actually deploy
  in the real world, they must be tested under an intractable number of environmental
  conditions. We introduce RPOSST, an algorithm to select a small set of test cases
  from a larger pool based on a relatively small number of sample evaluations. RPOSST
  treats the test case selection problem as a two-player game and optimizes a solution
  with provable $k$-of-$N$ robustness, bounding the error relative to a test that
  used all the test cases in the pool. Empirical results demonstrate that RPOSST finds
  a small set of test cases that identify high quality policies in a toy one-shot
  game, poker datasets, and a high-fidelity racing simulator.
openreview: Z3P3BC5zLGd
title: Composing Efficient, Robust Tests for Policy Selection
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: morrill23a
month: 0
tex_title: Composing Efficient, Robust Tests for Policy Selection
firstpage: 1456
lastpage: 1466
page: 1456-1466
order: 1456
cycles: false
bibtex_author: Morrill, Dustin and Walsh, Thomas J. and Hernandez, Daniel and Wurman,
  Peter R. and Stone, Peter
author:
- given: Dustin
  family: Morrill
- given: Thomas J.
  family: Walsh
- given: Daniel
  family: Hernandez
- given: Peter R.
  family: Wurman
- given: Peter
  family: Stone
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/morrill23a/morrill23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/morrill23a/morrill23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
