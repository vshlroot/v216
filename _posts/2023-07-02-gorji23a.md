---
abstract: Despite the capacity of neural nets to learn arbitrary functions, models
  trained through gradient descent often exhibit a bias towards “simpler” functions.
  Various notions of simplicity have been introduced to characterize this behavior.
  Here, we focus on the case of neural networks with discrete (zero-one) inputs through
  the lens of their Fourier (Walsh-Hadamard) transforms, where the notion of simplicity
  can be captured through the degree of the Fourier coefficients. We empirically show
  that neural networks have a tendency to learn lower-degree frequencies. We show
  how this spectral bias towards simpler features can in fact hurt the neural network’s
  generalization on real-world datasets. To remedy this we propose a new scalable
  functional regularization scheme that aids the neural network to learn higher degree
  frequencies. Our regularizer also helps avoid erroneous identification of low-degree
  frequencies, which further improves generalization. We extensively evaluate our
  regularizer on synthetic datasets to gain insights into its behavior. Finally, we
  show significantly improved generalization on four different datasets compared to
  standard neural networks and other relevant baselines.
openreview: 43G1CrRrnZh
title: A scalable Walsh-Hadamard regularizer to overcome the low-degree spectral bias
  of neural networks
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gorji23a
month: 0
tex_title: A scalable {W}alsh-{H}adamard regularizer to overcome the low-degree spectral
  bias of neural networks
firstpage: 723
lastpage: 733
page: 723-733
order: 723
cycles: false
bibtex_author: Gorji, Ali and Amrollahi, Andisheh and Krause, Andreas
author:
- given: Ali
  family: Gorji
- given: Andisheh
  family: Amrollahi
- given: Andreas
  family: Krause
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/gorji23a/gorji23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/gorji23a/gorji23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
