---
abstract: This paper proposes a new metric to measure the calibration error of probabilistic
  binary classifiers, called test-based calibration error (TCE). TCE incorporates
  a novel loss function based on a statistical test to examine the extent to which
  model predictions differ from probabilities estimated from data. It offers (i) a
  clear interpretation, (ii) a consistent scale that is unaffected by class imbalance,
  and (iii) an enhanced visual representation with respect to the standard reliability
  diagram. In addition, we introduce an optimality criterion for the binning procedure
  of calibration error metrics based on a minimal estimation error of the empirical
  probabilities. We provide a novel computational algorithm for optimal bins under
  bin-size constraints. We demonstrate properties of TCE through a range of experiments,
  including multiple real-world imbalanced datasets and ImageNet 1000.
openreview: qQ8b_f3g-4
title: 'TCE: A Test-Based Approach to Measuring Calibration Error'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: matsubara23a
month: 0
tex_title: "{TCE}: A Test-Based Approach to Measuring Calibration Error"
firstpage: 1390
lastpage: 1400
page: 1390-1400
order: 1390
cycles: false
bibtex_author: Matsubara, Takuo and Tax, Niek and Mudd, Richard and Guy, Ido
author:
- given: Takuo
  family: Matsubara
- given: Niek
  family: Tax
- given: Richard
  family: Mudd
- given: Ido
  family: Guy
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/matsubara23a/matsubara23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/matsubara23a/matsubara23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
