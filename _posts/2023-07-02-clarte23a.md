---
abstract: Despite their incredible performance, it is well reported that deep neural
  networks tend to be overoptimistic about their prediction confidence. Finding effective
  and efficient calibration methods for neural networks is therefore an important
  endeavour towards better uncertainty quantification in deep learning. In this manuscript,
  we introduce a novel calibration technique named expectation consistency (EC), consisting
  of a post-training rescaling of the last layer weights by enforcing that the average
  validation confidence coincides with the average proportion of correct labels. First,
  we show that the EC method achieves similar calibration performance to temperature
  scaling (TS) across different neural network architectures and data sets, all while
  requiring similar validation samples and computational resources. However, we argue
  that EC provides a principled method grounded on a Bayesian optimality principle
  known as the Nishimori identity. Next, we provide an asymptotic characterization
  of both TS and EC in a synthetic setting and show that their performance crucially
  depends on the target function. In particular, we discuss examples where EC significantly
  outperforms TS.
openreview: XM3ir4kAt0
title: Expectation consistency for calibration of neural networks
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: clarte23a
month: 0
tex_title: Expectation consistency for calibration of neural networks
firstpage: 443
lastpage: 453
page: 443-453
order: 443
cycles: false
bibtex_author: Clart\'e, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'a,
  Lenka
author:
- given: Lucas
  family: Clarté
- given: Bruno
  family: Loureiro
- given: Florent
  family: Krzakala
- given: Lenka
  family: Zdeborová
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/clarte23a/clarte23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/clarte23a/clarte23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
