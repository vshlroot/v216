---
abstract: How can humans stay in control of advanced artificial intelligence systems?
  One proposal is corrigibility, which requires the agent to follow the instructions
  of a human overseer, without inappropriately influencing them. In this paper, we
  formally define a variant of corrigibility called shutdown instructability, and
  show that it implies appropriate shutdown behavior, retention of human autonomy,
  and avoidance of user harm. We also analyse the related concepts of non-obstruction
  and shutdown alignment, three previously proposed algorithms for human control,
  and one new algorithm.
openreview: wFZQEFyBO92
title: 'Human Control: Definitions and Algorithms'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: carey23a
month: 0
tex_title: 'Human Control: Definitions and Algorithms'
firstpage: 271
lastpage: 281
page: 271-281
order: 271
cycles: false
bibtex_author: Carey, Ryan and Everitt, Tom
author:
- given: Ryan
  family: Carey
- given: Tom
  family: Everitt
date: 2023-07-02
address:
container-title: Proceedings of the Thirty-Nineth Conference on Uncertainty in Artificial
  Intelligence
volume: '216'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 2
pdf: https://proceedings.mlr.press/v216/carey23a/carey23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v216/carey23a/carey23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
